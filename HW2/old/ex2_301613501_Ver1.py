# -*- coding: utf-8 -*-
"""Math_for_DS_and_SP_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GarEsJqAlTXlDu4Ib265ZgI4LFeZ2ZqR

# Mathematical Method for DS and PS
## HW 2
### Question 1
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy as sc
from scipy import stats
from scipy.sparse.linalg import eigsh
from scipy.sparse.linalg import eigs
import cvxpy as cp

from ast import While

# Generate a random symmetric matrix A of size n x n
n = 1000

iter = 0
iter_max = 2000
tolerance = 10e-6
err_hist=[]

M = np.random.normal(0,1,size=(n,n))
A = (M @ M.T)/2

# Compute the ground truth leading eigenvector u_ref using eigsh()
eval_true, u_ref = eigsh(A, k=1, which='LA')

u_est = np.random.normal(0,1,size=(n,1))

PEL = []
NEL = []

while True:
  
  u_est_hat = A @ u_est
  u_est_hat_norm = np.linalg.norm(u_est_hat, ord=2)  
  
  u_est = u_est_hat / u_est_hat_norm
  u_est_norm = np.linalg.norm(u_est, ord=2)
  
  pos_err = np.linalg.norm(u_est - u_ref,ord=2) / np.linalg.norm(u_ref, ord=2)
  PEL = np.append(PEL, pos_err)
  neg_err = np.linalg.norm(-u_est - u_ref,ord=2) / np.linalg.norm(u_ref, ord=2)
  NEL = np.append(NEL, neg_err)
  err = min(pos_err,neg_err)

  err_hist = np.append(err_hist, err)
    
  # breaking the loop conditions
  if ((iter >= iter_max)):# or (np.abs(u_norm-u_hat_norm)<tolerance) or ((iter > 1) and (np.abs(err[iter]-err[iter-1])<(tolerance/10)))):
    break

  iter+=1

w2, u2 = eigsh(A, k=2, which='LA')
L1 = w2[0]
L2 = w2[1]
expected_slope = np.log10(L1/L2)
slope, intercept = np.polyfit(range(iter+1), np.log(err_hist), 1)

print('\nExpected slope: {:.2}'.format(expected_slope))
print('Actual slope: {:.2}'.format(slope))

print('\nTotal Number of iterations: {}'.format(iter))



plt.figure()
plt.semilogy(range(iter+1), err_hist, 'r')

plt.grid()
plt.ylabel('Relative Error')
plt.xlabel('Iterations')
plt.title('Relative error with slope {:.3}'.format(slope))
plt.show()

fig, ax = plt.subplots(nrows=1, ncols=2)
ax = ax.ravel()

ax[0].semilogy(range(iter+1), PEL, color='r')
ax[0].set_title('POS Relative Error '), ax[0].axis('on')

ax[1].semilogy(range(iter+1), NEL, color='r')
ax[1].set_title('NEG Relative Error '), ax[1].axis('on')

plt.tight_layout()
plt.show()



L2

"""### Question 2
#### A
"""

Tg = [0.01, 0.1, 1, 10] #kernel variance
n = 2000 #observations
m = 50
x = np.concatenate((np.ones(10), np.zeros(40)))
sigma_noise= 0
d = 2 # Diffusion dim

# Generate the Gaussian noise
eps = np.random.normal(0,sigma_noise,n)

# Draw n random circular shifts from a uniform distribution
l = np.random.randint(0, n, n)

fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(7.5, 7.5))
ax = ax.ravel()

for idx_tg,tg in enumerate(Tg):
  # The roll matrix Rx
  Rx = np.roll(x,l[0])
  for j in range(n-1):
    Rx = np.column_stack((Rx, np.roll(x,l[j+1])))

  # Generate the observations Y according to the model
  Y = Rx + eps.T

  # Calculate weights using the kernel
  W = np.zeros((n,n))
  for i in range(n):
    for j in range(i+1,n):
      Yi = Y[:, i]
      Yj = Y[:, j]
      dist = np.linalg.norm(Yi-Yj)
      W[i,j] = W[j,i] = np.exp(-dist**2/tg)

  # Diagonal matrix determining the degree of each vertex
  deg = W.sum(axis=1)
  deg_inv = 1/deg

  D = np.diag(deg)
  D_inv = np.diag(deg_inv)
  D_sqrt = D ** 0.5
  D_inv_sqrt = D_inv ** 0.5

  # Random walker probabilities matrix
  M = D_inv @ W
  S = D_sqrt @ M @ D_inv_sqrt

  eigenvalues, eigenvectors = eigsh(S, k=d+1, which='LA')
  PHI = D_inv_sqrt @ eigenvectors.real
  PSI = D_sqrt @ eigenvectors.real
  diff_coordinates = PHI[:,:d]

  ax[idx_tg].plot(diff_coordinates[:, 0], diff_coordinates[:, 1], 'x', color='r')
  ax[idx_tg].set_title('tg = {}'.format(tg)), ax[idx_tg].axis('on')

  # Set the tick label formatter for both the x-axis and the y-axis
  formatter = ax[idx_tg].xaxis.get_major_formatter()
  formatter.set_powerlimits((-1, 1))
  formatter.set_scientific(True)
  formatter.set_useOffset(False)

  formatter = ax[idx_tg].yaxis.get_major_formatter()
  formatter.set_powerlimits((-1, 1))
  formatter.set_scientific(True)
  formatter.set_useOffset(False)

plt.tight_layout()
plt.show()

"""#### B"""

tg = 1 #kernel variance
n = 2000 #observations
m = 50
x = np.concatenate((np.ones(10), np.zeros(40)))
sigma_noise = [0.01, 0.1, 1, 10]
d = 2 # Diffusion dim


# Draw n random circular shifts from a uniform distribution
l = np.random.randint(0, n, n)

fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(7.5, 7.5))
ax = ax.ravel()

for idx_s,s in enumerate(sigma_noise):
  # Generate the Gaussian noise
  eps = np.random.normal(0,s,n)
  # The roll matrix Rx
  Rx = np.roll(x,l[0])
  for j in range(n-1):
    Rx = np.column_stack((Rx, np.roll(x,l[j+1])))

  # Generate the observations Y according to the model
  Y = Rx + eps.T

  # Calculate weights using the kernel
  W = np.zeros((n,n))
  for i in range(n):
    for j in range(i+1,n):
      Yi = Y[:, i]
      Yj = Y[:, j]
      dist = np.linalg.norm(Yi-Yj)
      W[i,j] = W[j,i] = np.exp(-dist**2/tg)

  # Diagonal matrix determining the degree of each vertex
  deg = W.sum(axis=1)
  deg_inv = 1/deg

  D = np.diag(deg)
  D_inv = np.diag(deg_inv)
  D_sqrt = D ** 0.5
  D_inv_sqrt = D_inv ** 0.5

  # Random walker probabilities matrix
  M = D_inv @ W
  S = D_sqrt @ M @ D_inv_sqrt

  eigenvalues, eigenvectors = eigsh(S, k=d+1, which='LA')
  PHI = D_inv_sqrt @ eigenvectors.real
  PSI = D_sqrt @ eigenvectors.real
  diff_coordinates = PHI[:,:d]

  ax[idx_s].plot(diff_coordinates[:, 0], diff_coordinates[:, 1], 'x', color='r')
  ax[idx_s].set_title('sigma = {}'.format(s)), ax[idx_s].axis('on')

  # Set the tick label formatter for both the x-axis and the y-axis
  formatter = ax[idx_s].xaxis.get_major_formatter()
  formatter.set_powerlimits((-1, 1))
  formatter.set_scientific(True)
  formatter.set_useOffset(False)

  formatter = ax[idx_s].yaxis.get_major_formatter()
  formatter.set_powerlimits((-1, 1))
  formatter.set_scientific(True)
  formatter.set_useOffset(False)


plt.tight_layout()
plt.show()

"""### Question 3"""

import numpy as np
import matplotlib.pyplot as plt
import scipy as sc
from scipy.sparse.linalg import eigsh
import cvxpy as cp

def simple_graph(An=20, Bn=20):
  G_simple = np.concatenate((np.ones(An), np.zeros(Bn))) # 1 if belong to A and 0 to B
  G_simple_x, G_simple_y = np.meshgrid(G_simple, G_simple)
  G_simple_2D = np.logical_xor(G_simple_x,G_simple_y)
        
  return G_simple_2D.astype(int)

def random_graph(An=20, Bn=20, p=0.5):
  Gn = An + Bn # Total nodes of in the graph
  G_rand = np.zeros((Gn, Gn))
  for i in range(Gn):
    for j in range(Gn):
      # Check if the vertices belong to the same set
      same_set = (i < An and j < An) or (i >= An and j >= An)
      # Generate a random number between 0 and 1
      r = np.random.rand()
      # Create an edge between the vertices with probability p if they belong to the same set, or with probability 1 - p if they belong to different sets
      if (same_set and r < p) or (not same_set and r < 1 - p):
        G_rand[i, j] = 1

  return G_rand

p=0.1 #probability
An = 20 # Nodes of A vertices
Bn = 20 # Nodes of B vertices

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7.5, 7.5))
ax = ax.ravel()

im1 = ax[0].imshow(simple_graph(An,Bn), cmap='binary')
ax[0].set_title('True Graph'), ax[0].axis('on')
fig.colorbar(im1, ax=ax[0], shrink=0.375)

im2 = ax[1].imshow(random_graph(An,Bn,p), cmap='binary')
ax[1].set_title('Random Graph @ p = {}'.format(p)), ax[1].axis('on')
fig.colorbar(im2, ax=ax[1], shrink=0.375)

plt.show()

An = 20 # Nodes of A vertices
Bn = 20 # Nodes of B vertices
P = np.linspace(0.1,0.5,50)
trials = 50
true_clusters = simple_graph(An,Bn)

errors = np.zeros((len(P), trials))


for t in range(trials):
  # Figure decleration
  fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 8))
  ax = ax.ravel()

  # Ground Truth Graph
  im1 = ax[0].imshow(true_clusters, cmap='binary')
  ax[0].set_title('True Graph'), ax[0].axis('on')
  fig.colorbar(im1, ax=ax[0], shrink=0.375)

  for i,p in enumerate(P):
    G = random_graph(An,Bn,p)
    n = G.shape[0] # number of verticies

    # Create decision variables for SDP relaxation
    X = cp.Variable((n, n), symmetric=True)

    # Define the objective function
    objective = cp.Maximize(0.5 * cp.sum(cp.multiply(G, (1 - X))))

    # Define the constraints
    constraints = [X >> 0,
                    cp.diag(X) == cp.Parameter((n,), value=np.ones(n))]
    
    # Form and solve the SDP relaxation
    prob = cp.Problem(objective, constraints)
    prob.solve()

    # Extract the solution
    solution = X.value

    # Since the solution is +/-1 by definition, need to manipulate all the neg vals to zeros 
    G_estimate = np.where(solution>0, 1, 0)
    
    # Calculate the average clustering error
    error = np.sum(np.not_equal(G_estimate,true_clusters))/n

    # Add the error to the list of errors
    errors[i,t] = error

    # Best p-value graph
    if i==0:
      im2 = ax[1].imshow(G_estimate, cmap='binary')
      ax[1].set_title('Max Cut Cluster @ p = {:.1}'.format(p)), ax[1].axis('on')
      fig.colorbar(im2, ax=ax[1], shrink=0.375)
    

  # Worst p-value graph
  im3 = ax[2].imshow(G_estimate, cmap='binary')
  ax[2].set_title('Max Cut Cluster @ p = {:.1}'.format(p)), ax[2].axis('on')
  fig.colorbar(im3, ax=ax[2], shrink=0.375)
  plt.show()


errors = np.mean(errors, axis=1)
# Plot Error
plt.figure(figsize=(11, 4))
plt.plot(P, errors, 'r')
plt.title('Average Error for {} Trials'.format(trials))
plt.xlabel('Probability')
plt.ylabel('Average clustering error')
plt.grid()
plt.show()

"""### Question 4"""

# Check if a matrix is symmetric
def is_symmetric(matrix):
  return np.allclose(matrix, matrix.conj().T)

# Generate n random angles from the interval [0, 2Ï€)
n = 100
angles = np.random.uniform(0, 2*np.pi, n)

P = np.linspace(0,0.5, 10)
trials = 50
spectr_errors = np.zeros((len(P), trials))
sdp_errors = np.zeros((len(P), trials))
rnd = 2
for t in range(trials):
  
  # Generate the rank-one Hermitian matrix H
  h = np.exp(1j * angles)
  H = np.outer(h, h.conj())
  H_corrupt = H.copy()
  
  for px, p in enumerate(P):
    
    # Corrupt H with probability p according to the "outliers model"
    outliers = np.random.binomial(1, p, size=(n, n))
    outliers = np.tril(outliers, -1)  # only consider upper triangular part
    alphas = np.random.uniform(0, 2*np.pi, np.sum(outliers))
    H_corrupt[outliers == 1] = np.exp(1j * alphas)
    H_corrupt = (H_corrupt + H_corrupt.conj().T)/2 # make H_corrupt Hermitian
    
    ##### Spectral Relexation Method #####

    # Calculate the estimate rotation vector h_hat
    eval, evec = np.linalg.eig(H_corrupt)
    max_idx = np.argmax(np.abs(eval))
    evec_lead = evec[:, max_idx]

    h_hat = evec_lead

    h_hat_al = h_hat * (h_hat.conj().T @ h)
    angles_hat_al = np.mod(np.angle(h_hat_al), 2*np.pi)

    angles_hat_al_r = np.round(angles_hat_al,rnd)
    angles_r = np.round(angles,rnd)

    err_spec =  np.sum(np.not_equal(angles_hat_al_r, angles_r))/n
    spectr_errors[px,t] = err_spec

    ##### SDP Method #####
    # Create decision variables for SDP relaxation
    H_cp = cp.Parameter((n, n), complex=True, value=H_corrupt)
    Z = cp.Variable((n, n), complex=True)   
    
    # Define the constraints
    constraints = [Z >> 0, 
                    cp.diag(Z) == cp.Parameter((n,), 
                    value = np.ones(n), complex=True),
                    Z == Z.H]

    # Form Objective
    objective = cp.Maximize(cp.real(cp.trace(H_cp@Z)))
    # Form and solve the SDP relaxation
    Problem = cp.Problem(objective, constraints)
    Problem.solve()
    
    # Extract the solution
    Z_sdp = Z.value

    # Z = zz*
    sdp_eval, sdp_evec = np.linalg.eig(Z_sdp)
    max_idx = np.argmax(np.abs(sdp_eval))
    sdp_evec_lead = sdp_evec[:, max_idx]

    sdp_h_hat = sdp_evec_lead

    sdp_h_hat_al = sdp_h_hat * (sdp_h_hat.conj().T @ h)
    sdp_angles_hat_al = np.mod(np.angle(sdp_h_hat_al), 2*np.pi)

    sdp_angles_hat_al_r = np.round(sdp_angles_hat_al,rnd)
    angles_r = np.round(angles,rnd)

    err_sdp = np.sum(np.not_equal(sdp_angles_hat_al_r, angles_r))/n
    sdp_errors[px,t] = err_sdp

spectr_errors = np.mean(spectr_errors, axis=1)
sdp_errors = np.mean(sdp_errors, axis=1)


plt.figure()
plt.plot(P, spectr_errors, 'r', label='Spectral Method')
plt.plot(P, sdp_errors, 'g', label='SDP Method') 
plt.title('Average Error for {} Trials'.format(trials))
plt.xlabel('Probability')
plt.ylabel('Avg. error')
plt.legend()
plt.grid()
plt.show()

